#!/usr/bin/env python3
"""
ExplosiveDetector v1.2 å®‰è£…å’Œè®¾ç½®è„šæœ¬
ç”¨äºåˆå§‹åŒ–MLæ¨¡å‹ã€åˆ›å»ºå¿…è¦ç›®å½•å’Œé…ç½®ç¯å¢ƒ
"""

import os
import sys
import subprocess
import logging
from pathlib import Path
import json

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ExplosiveDetectorSetup:
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.models_dir = self.base_dir / "models"
        self.logs_dir = self.base_dir / "logs"
        self.data_dir = self.base_dir / "data"

    def check_python_version(self):
        """æ£€æŸ¥Pythonç‰ˆæœ¬"""
        if sys.version_info < (3, 8):
            logger.error("éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
            return False
        logger.info(f"Pythonç‰ˆæœ¬æ£€æŸ¥é€šè¿‡: {sys.version}")
        return True

    def install_dependencies(self):
        """å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…"""
        required_packages = [
            "scikit-learn>=1.3.0",
            "joblib>=1.3.0",
            "numpy>=1.24.0",
            "pandas>=2.0.0",
            "ccxt>=4.0.0",
            "vaderSentiment>=3.3.2",
            "textblob>=0.17.1",
            "requests>=2.28.0"
        ]

        optional_packages = [
            "xgboost>=1.7.0",
            "lightgbm>=4.0.0",
            "catboost>=1.2.0",
            "feature-engine>=1.6.0",
            "optuna>=3.0.0"
        ]

        logger.info("å¼€å§‹å®‰è£…å¿…éœ€ä¾èµ–...")
        for package in required_packages:
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", package])
                logger.info(f"âœ… å·²å®‰è£…: {package}")
            except subprocess.CalledProcessError as e:
                logger.error(f"âŒ å®‰è£…å¤±è´¥: {package} - {e}")
                return False

        logger.info("å¼€å§‹å®‰è£…å¯é€‰ä¾èµ–...")
        for package in optional_packages:
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", package])
                logger.info(f"âœ… å·²å®‰è£… (å¯é€‰): {package}")
            except subprocess.CalledProcessError as e:
                logger.warning(f"âš ï¸ å¯é€‰åŒ…å®‰è£…å¤±è´¥: {package} - {e}")

        return True

    def create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„"""
        directories = [
            self.models_dir,
            self.logs_dir,
            self.data_dir,
            self.data_dir / "cache",
            self.data_dir / "training",
            self.data_dir / "exports"
        ]

        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            logger.info(f"âœ… ç›®å½•å·²åˆ›å»º: {directory}")

        return True

    def create_sample_training_data(self):
        """åˆ›å»ºç¤ºä¾‹è®­ç»ƒæ•°æ®"""
        import numpy as np
        import pandas as pd

        # ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
        np.random.seed(42)
        n_samples = 1000

        features = {
            'rsi': np.random.uniform(20, 80, n_samples),
            'macd_hist': np.random.uniform(-0.1, 0.1, n_samples),
            'bb_position': np.random.uniform(0, 1, n_samples),
            'vol_ratio': np.random.uniform(0.5, 5.0, n_samples),
            'roc_1h': np.random.uniform(-0.1, 0.1, n_samples),
            'roc_4h': np.random.uniform(-0.2, 0.2, n_samples),
            'atr_percent': np.random.uniform(1, 10, n_samples),
            'mfi': np.random.uniform(20, 80, n_samples),
            'willr': np.random.uniform(-100, 0, n_samples),
            'stoch_k': np.random.uniform(0, 100, n_samples),
            'news_sentiment': np.random.uniform(-1, 1, n_samples),
            'news_count': np.random.randint(0, 20, n_samples),
            'social_heat': np.random.uniform(0, 1, n_samples),
            'social_sentiment': np.random.uniform(-1, 1, n_samples),
            'whale_transactions': np.random.randint(0, 50, n_samples),
            'exchange_flow_ratio': np.random.uniform(0.5, 2.0, n_samples),
            'oi_change': np.random.uniform(-50, 50, n_samples),
            'funding_rate': np.random.uniform(-0.01, 0.01, n_samples),
            'long_short_ratio': np.random.uniform(0.3, 3.0, n_samples),
            'btc_correlation': np.random.uniform(-1, 1, n_samples)
        }

        df = pd.DataFrame(features)

        # ç”Ÿæˆæ ‡ç­¾ (1 = æš´æ¶¨, 0 = ä¸æš´æ¶¨)
        # å¤æ‚çš„é€»è¾‘æ¥æ¨¡æ‹ŸçœŸå®æƒ…å†µ
        explosion_probability = (
            (df['vol_ratio'] > 2.0).astype(int) * 0.3 +
            (df['roc_1h'] > 0.05).astype(int) * 0.25 +
            (df['news_sentiment'] > 0.2).astype(int) * 0.2 +
            (df['social_heat'] > 0.5).astype(int) * 0.15 +
            (df['whale_transactions'] > 10).astype(int) * 0.1
        )

        df['target'] = (explosion_probability > 0.6).astype(int)

        # ä¿å­˜è®­ç»ƒæ•°æ®
        training_file = self.data_dir / "training" / "sample_training_data.csv"
        df.to_csv(training_file, index=False)
        logger.info(f"âœ… ç¤ºä¾‹è®­ç»ƒæ•°æ®å·²åˆ›å»º: {training_file}")

        return True

    def initialize_ml_models(self):
        """åˆå§‹åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹"""
        try:
            from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
            from sklearn.linear_model import LogisticRegression
            from sklearn.preprocessing import StandardScaler
            from sklearn.model_selection import train_test_split
            import pandas as pd
            import joblib

            # åŠ è½½è®­ç»ƒæ•°æ®
            training_file = self.data_dir / "training" / "sample_training_data.csv"
            if not training_file.exists():
                logger.error("è®­ç»ƒæ•°æ®ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œcreate_sample_training_data")
                return False

            df = pd.read_csv(training_file)
            X = df.drop(['target'], axis=1)
            y = df['target']

            # åˆ†å‰²æ•°æ®
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )

            # æ ‡å‡†åŒ–ç‰¹å¾
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            # åˆ›å»ºé›†æˆæ¨¡å‹
            rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)
            gb = GradientBoostingClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)
            lr = LogisticRegression(random_state=42, max_iter=1000)

            voting_clf = VotingClassifier(
                estimators=[('rf', rf), ('gb', gb), ('lr', lr)],
                voting='probability'
            )

            # è®­ç»ƒæ¨¡å‹
            logger.info("å¼€å§‹è®­ç»ƒMLæ¨¡å‹...")
            voting_clf.fit(X_train_scaled, y_train)

            # è¯„ä¼°æ¨¡å‹
            from sklearn.metrics import accuracy_score, classification_report
            y_pred = voting_clf.predict(X_test_scaled)
            accuracy = accuracy_score(y_test, y_pred)

            logger.info(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.4f}")
            logger.info("åˆ†ç±»æŠ¥å‘Š:")
            logger.info(f"\n{classification_report(y_test, y_pred)}")

            # ä¿å­˜æ¨¡å‹
            model_path = self.models_dir / "explosive_detector_v1_2.pkl"
            scaler_path = self.models_dir / "explosive_detector_v1_2_scaler.pkl"

            joblib.dump(voting_clf, model_path)
            joblib.dump(scaler, scaler_path)

            logger.info(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
            logger.info(f"âœ… æ ‡å‡†åŒ–å™¨å·²ä¿å­˜: {scaler_path}")

            # ä¿å­˜ç‰¹å¾åˆ—è¡¨
            feature_columns = X.columns.tolist()
            features_path = self.models_dir / "feature_columns.json"
            with open(features_path, 'w') as f:
                json.dump(feature_columns, f)

            logger.info(f"âœ… ç‰¹å¾åˆ—è¡¨å·²ä¿å­˜: {features_path}")

            return True

        except ImportError as e:
            logger.error(f"MLåº“å¯¼å…¥å¤±è´¥: {e}")
            return False
        except Exception as e:
            logger.error(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def create_config_templates(self):
        """åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿"""
        # APIé…ç½®æ¨¡æ¿
        api_config = {
            "news_apis": {
                "cryptopanic": {
                    "api_key": "your_cryptopanic_api_key_here",
                    "enabled": False
                },
                "newsapi": {
                    "api_key": "your_newsapi_key_here",
                    "enabled": False
                }
            },
            "social_apis": {
                "twitter": {
                    "bearer_token": "your_twitter_bearer_token_here",
                    "enabled": False
                },
                "reddit": {
                    "client_id": "your_reddit_client_id_here",
                    "client_secret": "your_reddit_secret_here",
                    "enabled": False
                }
            },
            "onchain_apis": {
                "glassnode": {
                    "api_key": "your_glassnode_api_key_here",
                    "enabled": False
                },
                "etherscan": {
                    "api_key": "your_etherscan_api_key_here",
                    "enabled": False
                }
            }
        }

        api_config_path = self.base_dir / "api_config_template.json"
        with open(api_config_path, 'w') as f:
            json.dump(api_config, f, indent=2)

        logger.info(f"âœ… APIé…ç½®æ¨¡æ¿å·²åˆ›å»º: {api_config_path}")

        return True

    def run_setup(self):
        """è¿è¡Œå®Œæ•´çš„è®¾ç½®æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹ExplosiveDetector v1.2è®¾ç½®...")

        steps = [
            ("æ£€æŸ¥Pythonç‰ˆæœ¬", self.check_python_version),
            ("å®‰è£…ä¾èµ–åŒ…", self.install_dependencies),
            ("åˆ›å»ºç›®å½•ç»“æ„", self.create_directories),
            ("åˆ›å»ºç¤ºä¾‹è®­ç»ƒæ•°æ®", self.create_sample_training_data),
            ("åˆå§‹åŒ–MLæ¨¡å‹", self.initialize_ml_models),
            ("åˆ›å»ºé…ç½®æ¨¡æ¿", self.create_config_templates)
        ]

        for step_name, step_func in steps:
            logger.info(f"æ‰§è¡Œæ­¥éª¤: {step_name}")
            if not step_func():
                logger.error(f"âŒ æ­¥éª¤å¤±è´¥: {step_name}")
                return False
            logger.info(f"âœ… æ­¥éª¤å®Œæˆ: {step_name}")

        logger.info("ğŸ‰ ExplosiveDetector v1.2è®¾ç½®å®Œæˆï¼")
        logger.info("\nä¸‹ä¸€æ­¥æ“ä½œ:")
        logger.info("1. ç¼–è¾‘api_config_template.jsoné…ç½®ä½ çš„APIå¯†é’¥")
        logger.info("2. è¿è¡Œå›æµ‹ä»¥éªŒè¯ç­–ç•¥: freqtrade backtesting --strategy ExplosiveDetector_v1_2")
        logger.info("3. å¯åŠ¨å®æ—¶ç›‘æ§: freqtrade trade --strategy ExplosiveDetector_v1_2 --dry-run")

        return True

if __name__ == "__main__":
    setup = ExplosiveDetectorSetup()
    success = setup.run_setup()
    sys.exit(0 if success else 1)