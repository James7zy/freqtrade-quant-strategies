import logging
import numpy as np
import pandas as pd
import talib.abstract as ta
import pandas_ta as pta
from datetime import datetime, timedelta
from pandas import DataFrame
from typing import Optional, Dict, List, Tuple
from freqtrade.strategy.interface import IStrategy
from freqtrade.strategy import merge_informative_pair, DecimalParameter, IntParameter, BooleanParameter
import freqtrade.vendor.qtpylib.indicators as qtpylib
import requests
import json
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from collections import defaultdict
import time
import hashlib
import pickle
import os
from pathlib import Path

# å°è¯•å¯¼å…¥æœºå™¨å­¦ä¹ ä¾èµ–
try:
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import classification_report, accuracy_score
    from sklearn.pipeline import Pipeline
    import joblib
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

# æƒ…ç»ªåˆ†æä¾èµ–
try:
    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
    VADER_AVAILABLE = True
except ImportError:
    VADER_AVAILABLE = False

# é«˜çº§æ•°æ®å¤„ç†
try:
    import ccxt
    CCXT_AVAILABLE = True
except ImportError:
    CCXT_AVAILABLE = False

logger = logging.getLogger(__name__)

class ExplosiveDetector_v1_2(IStrategy):
    """
    24å°æ—¶æš´æ¶¨å¸ç§æ£€æµ‹ç­–ç•¥ v1.2
    æ–°å¢åŠŸèƒ½:
    - æœºå™¨å­¦ä¹ æ¨¡å‹é›†æˆ
    - å¸ç§ç›¸å…³æ€§åˆ†æ
    - é“¾ä¸Šæ•°æ®é›†æˆ
    - æœŸè´§æŒä»“é‡åˆ†æ
    - è‡ªå®šä¹‰ç­›é€‰æ¡ä»¶
    """

    # åŸºç¡€é…ç½®
    timeframe = '1h'
    startup_candle_count: int = 200
    stoploss = -0.99
    can_short = False
    process_only_new_candles = True
    use_exit_signal = False
    ignore_roi_if_entry_signal = True
    minimal_roi = {"0": 10.0}

    # v1.0 & v1.1 å‚æ•°
    volume_surge_threshold = DecimalParameter(2.0, 5.0, default=3.0, space="buy", optimize=True)
    price_momentum_threshold = DecimalParameter(0.05, 0.20, default=0.10, space="buy", optimize=True)
    rsi_recovery_threshold = DecimalParameter(25.0, 45.0, default=35.0, space="buy", optimize=True)
    breakout_strength_threshold = DecimalParameter(1.5, 3.0, default=2.0, space="buy", optimize=True)
    volume_lookback = IntParameter(6, 24, default=12, space="buy", optimize=True)
    momentum_lookback = IntParameter(3, 12, default=6, space="buy", optimize=True)
    sentiment_weight = DecimalParameter(0.1, 0.5, default=0.25, space="buy", optimize=True)
    social_heat_weight = DecimalParameter(0.1, 0.4, default=0.20, space="buy", optimize=True)
    news_lookback_hours = IntParameter(6, 24, default=12, space="buy", optimize=True)

    # v1.2 æ–°å¢å‚æ•°
    ml_model_weight = DecimalParameter(0.2, 0.6, default=0.35, space="buy", optimize=True)
    correlation_threshold = DecimalParameter(0.3, 0.8, default=0.6, space="buy", optimize=True)
    onchain_weight = DecimalParameter(0.1, 0.4, default=0.25, space="buy", optimize=True)
    futures_oi_weight = DecimalParameter(0.1, 0.3, default=0.20, space="buy", optimize=True)

    # åŠŸèƒ½å¼€å…³
    enable_sentiment_analysis = BooleanParameter(default=True, space="buy", optimize=False)
    enable_social_analysis = BooleanParameter(default=True, space="buy", optimize=False)
    enable_ml_predictions = BooleanParameter(default=True, space="buy", optimize=False)
    enable_correlation_analysis = BooleanParameter(default=True, space="buy", optimize=False)
    enable_onchain_analysis = BooleanParameter(default=True, space="buy", optimize=False)
    enable_futures_analysis = BooleanParameter(default=True, space="buy", optimize=False)

    # è‡ªå®šä¹‰ç­›é€‰æ¡ä»¶
    min_market_cap_usd = IntParameter(10000000, 1000000000, default=100000000, space="buy", optimize=False)  # 1äº¿ç¾å…ƒ
    min_24h_volume_usd = IntParameter(1000000, 100000000, default=10000000, space="buy", optimize=False)     # 1000ä¸‡ç¾å…ƒ
    max_correlation_btc = DecimalParameter(0.5, 0.95, default=0.85, space="buy", optimize=False)

    def __init__(self, config: dict) -> None:
        super().__init__(config)

        # åˆå§‹åŒ–ç»„ä»¶
        self.sentiment_analyzer = None
        if VADER_AVAILABLE and self.enable_sentiment_analysis.value:
            self.sentiment_analyzer = SentimentIntensityAnalyzer()

        # ç¼“å­˜ç³»ç»Ÿ
        self.news_cache = {}
        self.social_cache = {}
        self.onchain_cache = {}
        self.futures_cache = {}
        self.correlation_cache = {}
        self.cache_ttl = 1800
        self.cache_lock = threading.Lock()

        # æœºå™¨å­¦ä¹ æ¨¡å‹
        self.ml_model = None
        self.ml_scaler = None
        self.feature_columns = []
        self.model_path = "models/explosive_detector_v1_2.pkl"
        self.training_data = []
        self.model_last_trained = None

        # å¹¶è¡Œå¤„ç†
        self.max_workers = 8
        self.api_rate_limit = 0.15
        self.last_api_call = {}

        # å¸ç§æ•°æ®ç¼“å­˜
        self.market_data_cache = {}
        self.correlation_matrix = None
        self.correlation_last_update = None

        # åˆå§‹åŒ–MLæ¨¡å‹
        if ML_AVAILABLE and self.enable_ml_predictions.value:
            self._initialize_ml_models()

    def _initialize_ml_models(self):
        """åˆå§‹åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹"""
        try:
            # å°è¯•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹
            if os.path.exists(self.model_path):
                self.ml_model = joblib.load(self.model_path)
                self.ml_scaler = joblib.load(self.model_path.replace('.pkl', '_scaler.pkl'))
                logger.info("å·²åŠ è½½é¢„è®­ç»ƒMLæ¨¡å‹")
            else:
                # åˆ›å»ºæ–°æ¨¡å‹
                self._create_ml_model()
        except Exception as e:
            logger.warning(f"MLæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ml_model = None

    def _create_ml_model(self):
        """åˆ›å»ºæœºå™¨å­¦ä¹ æ¨¡å‹"""
        # é›†æˆå­¦ä¹ å™¨ç»„åˆ
        rf = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )

        gb = GradientBoostingClassifier(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42
        )

        lr = LogisticRegression(
            random_state=42,
            max_iter=1000
        )

        # æŠ•ç¥¨åˆ†ç±»å™¨
        self.ml_model = VotingClassifier(
            estimators=[
                ('rf', rf),
                ('gb', gb),
                ('lr', lr)
            ],
            voting='probability'
        )

        self.ml_scaler = StandardScaler()
        logger.info("å·²åˆ›å»ºæ–°çš„MLæ¨¡å‹")

    def _get_market_data(self, pair: str) -> Dict:
        """è·å–å¸‚åœºæ•°æ®"""
        cache_key = f"market_{pair}"
        if self._is_cache_valid(cache_key):
            return self.market_data_cache.get(cache_key, {})

        try:
            # æ¨¡æ‹Ÿå¸‚åœºæ•°æ®APIè°ƒç”¨
            market_data = {
                'market_cap_usd': np.random.randint(10000000, 50000000000),
                'volume_24h_usd': np.random.randint(1000000, 1000000000),
                'circulating_supply': np.random.randint(1000000, 100000000000),
                'price_change_24h': np.random.uniform(-20, 20),
                'price_change_7d': np.random.uniform(-40, 40),
                'timestamp': time.time()
            }

            with self.cache_lock:
                self.market_data_cache[cache_key] = market_data

            return market_data

        except Exception as e:
            logger.warning(f"è·å–{pair}å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            return {}

    def _calculate_correlation_matrix(self, pairs: List[str]) -> pd.DataFrame:
        """è®¡ç®—å¸ç§é—´ç›¸å…³æ€§çŸ©é˜µ"""
        if (self.correlation_matrix is not None and
            self.correlation_last_update and
            time.time() - self.correlation_last_update < 3600):  # 1å°æ—¶ç¼“å­˜
            return self.correlation_matrix

        try:
            # è·å–æ‰€æœ‰å¸ç§çš„ä»·æ ¼æ•°æ®
            price_data = {}
            for pair in pairs:
                df = self.dp.get_pair_dataframe(pair=pair, timeframe=self.timeframe)
                if len(df) > 100:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
                    price_data[pair] = df['close'].pct_change().dropna()

            if len(price_data) >= 2:
                # åˆ›å»ºä»·æ ¼å˜åŒ–DataFrame
                price_df = pd.DataFrame(price_data)

                # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
                self.correlation_matrix = price_df.corr()
                self.correlation_last_update = time.time()

                logger.info(f"å·²æ›´æ–°{len(pairs)}ä¸ªå¸ç§çš„ç›¸å…³æ€§çŸ©é˜µ")
                return self.correlation_matrix

        except Exception as e:
            logger.warning(f"è®¡ç®—ç›¸å…³æ€§çŸ©é˜µå¤±è´¥: {e}")

        return pd.DataFrame()

    def _get_onchain_data(self, pair: str) -> Dict:
        """è·å–é“¾ä¸Šæ•°æ®"""
        cache_key = self._get_cache_key(pair, 'onchain')
        if self._is_cache_valid(cache_key):
            with self.cache_lock:
                return self.onchain_cache.get(cache_key, {})

        coin_symbol = self._extract_coin_symbol(pair)
        onchain_data = {
            'whale_transactions': 0,
            'large_transfers_24h': 0,
            'exchange_inflow': 0.0,
            'exchange_outflow': 0.0,
            'holder_distribution': 0.0,
            'active_addresses': 0,
            'timestamp': time.time()
        }

        try:
            # æ¨¡æ‹Ÿé“¾ä¸Šæ•°æ®APIè°ƒç”¨
            self._rate_limit_api_call('onchain')

            # å®é™…å®ç°ä¸­åº”è°ƒç”¨å¦‚Glassnode, IntoTheBlockç­‰API
            onchain_data.update({
                'whale_transactions': np.random.randint(0, 50),
                'large_transfers_24h': np.random.randint(0, 100),
                'exchange_inflow': np.random.uniform(0, 10000000),
                'exchange_outflow': np.random.uniform(0, 15000000),
                'holder_distribution': np.random.uniform(0.3, 0.8),
                'active_addresses': np.random.randint(1000, 100000)
            })

        except Exception as e:
            logger.warning(f"è·å–{pair}é“¾ä¸Šæ•°æ®å¤±è´¥: {e}")

        with self.cache_lock:
            self.onchain_cache[cache_key] = onchain_data

        return onchain_data

    def _get_futures_data(self, pair: str) -> Dict:
        """è·å–æœŸè´§æ•°æ®"""
        cache_key = self._get_cache_key(pair, 'futures')
        if self._is_cache_valid(cache_key):
            with self.cache_lock:
                return self.futures_cache.get(cache_key, {})

        futures_data = {
            'open_interest': 0.0,
            'oi_change_24h': 0.0,
            'funding_rate': 0.0,
            'long_short_ratio': 0.5,
            'liquidations_24h': 0.0,
            'timestamp': time.time()
        }

        try:
            # æ¨¡æ‹ŸæœŸè´§æ•°æ®APIè°ƒç”¨
            self._rate_limit_api_call('futures')

            # å®é™…å®ç°ä¸­è°ƒç”¨Binance Futures, BitMEXç­‰API
            futures_data.update({
                'open_interest': np.random.uniform(10000000, 500000000),
                'oi_change_24h': np.random.uniform(-20, 20),
                'funding_rate': np.random.uniform(-0.01, 0.01),
                'long_short_ratio': np.random.uniform(0.3, 3.0),
                'liquidations_24h': np.random.uniform(0, 10000000)
            })

        except Exception as e:
            logger.warning(f"è·å–{pair}æœŸè´§æ•°æ®å¤±è´¥: {e}")

        with self.cache_lock:
            self.futures_cache[cache_key] = futures_data

        return futures_data

    def _prepare_ml_features(self, dataframe: DataFrame, pair: str) -> pd.DataFrame:
        """å‡†å¤‡MLæ¨¡å‹ç‰¹å¾"""
        try:
            latest = dataframe.iloc[-1]

            # åŸºç¡€æŠ€æœ¯ç‰¹å¾
            features = {
                'rsi': latest['rsi'],
                'macd_hist': latest['macd_hist'],
                'bb_position': latest['price_position_bb'],
                'vol_ratio': latest['vol_ratio_20'],
                'roc_1h': latest['roc_1h'],
                'roc_4h': latest['roc_4h'],
                'atr_percent': latest['atr_percent'],
                'mfi': latest['mfi'],
                'willr': latest['willr'],
                'stoch_k': latest['stoch_k']
            }

            # æ–°å¢ç‰¹å¾
            if 'news_sentiment_score' in dataframe.columns:
                features['news_sentiment'] = latest['news_sentiment_score']
                features['news_count'] = latest['news_count']

            if 'social_heat_index' in dataframe.columns:
                features['social_heat'] = latest['social_heat_index']
                features['social_sentiment'] = latest['social_sentiment_trend']

            # å¸‚åœºæ•°æ®ç‰¹å¾
            market_data = self._get_market_data(pair)
            if market_data:
                features['market_cap_log'] = np.log10(max(market_data.get('market_cap_usd', 1), 1))
                features['volume_24h_log'] = np.log10(max(market_data.get('volume_24h_usd', 1), 1))
                features['price_change_24h'] = market_data.get('price_change_24h', 0)

            # é“¾ä¸Šæ•°æ®ç‰¹å¾
            if self.enable_onchain_analysis.value:
                onchain_data = self._get_onchain_data(pair)
                features['whale_transactions'] = onchain_data.get('whale_transactions', 0)
                features['exchange_flow_ratio'] = (
                    onchain_data.get('exchange_outflow', 0) /
                    max(onchain_data.get('exchange_inflow', 1), 1)
                )

            # æœŸè´§æ•°æ®ç‰¹å¾
            if self.enable_futures_analysis.value:
                futures_data = self._get_futures_data(pair)
                features['oi_change'] = futures_data.get('oi_change_24h', 0)
                features['funding_rate'] = futures_data.get('funding_rate', 0)
                features['long_short_ratio'] = futures_data.get('long_short_ratio', 1)

            # ç›¸å…³æ€§ç‰¹å¾
            if self.enable_correlation_analysis.value and self.correlation_matrix is not None:
                btc_pair = 'BTC/USDT'
                if pair in self.correlation_matrix.columns and btc_pair in self.correlation_matrix.columns:
                    features['btc_correlation'] = self.correlation_matrix.loc[pair, btc_pair]
                else:
                    features['btc_correlation'] = 0.0

            return pd.DataFrame([features])

        except Exception as e:
            logger.warning(f"MLç‰¹å¾å‡†å¤‡å¤±è´¥: {e}")
            return pd.DataFrame()

    def _get_ml_prediction(self, features_df: pd.DataFrame) -> Dict:
        """è·å–MLæ¨¡å‹é¢„æµ‹"""
        if not ML_AVAILABLE or self.ml_model is None or features_df.empty:
            return {'prediction': 0, 'probability': 0.5, 'confidence': 0.0}

        try:
            # ç¡®ä¿ç‰¹å¾é¡ºåºä¸€è‡´
            if not self.feature_columns:
                self.feature_columns = features_df.columns.tolist()

            # é‡æ–°æ’åºç‰¹å¾åˆ—
            missing_cols = set(self.feature_columns) - set(features_df.columns)
            for col in missing_cols:
                features_df[col] = 0.0

            features_df = features_df[self.feature_columns]

            # ç‰¹å¾ç¼©æ”¾
            if self.ml_scaler:
                features_scaled = self.ml_scaler.transform(features_df)
            else:
                features_scaled = features_df.values

            # é¢„æµ‹
            prediction = self.ml_model.predict(features_scaled)[0]
            probabilities = self.ml_model.predict_proba(features_scaled)[0]

            return {
                'prediction': int(prediction),
                'probability': float(probabilities[1] if len(probabilities) > 1 else probabilities[0]),
                'confidence': float(max(probabilities))
            }

        except Exception as e:
            logger.warning(f"MLé¢„æµ‹å¤±è´¥: {e}")
            return {'prediction': 0, 'probability': 0.5, 'confidence': 0.0}

    def _apply_custom_filters(self, pair: str, signal_data: Dict) -> bool:
        """åº”ç”¨è‡ªå®šä¹‰ç­›é€‰æ¡ä»¶"""
        try:
            # å¸‚åœºæ•°æ®ç­›é€‰
            market_data = self._get_market_data(pair)

            # æœ€å°å¸‚å€¼ç­›é€‰
            market_cap = market_data.get('market_cap_usd', 0)
            if market_cap < self.min_market_cap_usd.value:
                return False

            # æœ€å°æˆäº¤é‡ç­›é€‰
            volume_24h = market_data.get('volume_24h_usd', 0)
            if volume_24h < self.min_24h_volume_usd.value:
                return False

            # BTCç›¸å…³æ€§ç­›é€‰
            if self.enable_correlation_analysis.value and self.correlation_matrix is not None:
                btc_pair = 'BTC/USDT'
                if (pair in self.correlation_matrix.columns and
                    btc_pair in self.correlation_matrix.columns):
                    correlation = abs(self.correlation_matrix.loc[pair, btc_pair])
                    if correlation > self.max_correlation_btc.value:
                        return False

            return True

        except Exception as e:
            logger.warning(f"è‡ªå®šä¹‰ç­›é€‰å¤±è´¥: {e}")
            return True

    # ç»§æ‰¿v1.1çš„æ–¹æ³•
    def _get_cache_key(self, pair: str, data_type: str) -> str:
        current_hour = datetime.now().replace(minute=0, second=0, microsecond=0)
        return f"{pair}_{data_type}_{current_hour.isoformat()}"

    def _is_cache_valid(self, cache_key: str) -> bool:
        with self.cache_lock:
            caches = [self.news_cache, self.social_cache, self.onchain_cache, self.futures_cache]
            for cache in caches:
                if cache_key in cache:
                    cache_time = cache[cache_key].get('timestamp', 0)
                    return time.time() - cache_time < self.cache_ttl
        return False

    def _rate_limit_api_call(self, api_name: str):
        current_time = time.time()
        last_call_time = self.last_api_call.get(api_name, 0)
        time_diff = current_time - last_call_time
        if time_diff < self.api_rate_limit:
            time.sleep(self.api_rate_limit - time_diff)
        self.last_api_call[api_name] = time.time()

    def _extract_coin_symbol(self, pair: str) -> str:
        return pair.split('/')[0].upper()

    # ç»§æ‰¿v1.1çš„å¤–éƒ¨æ•°æ®è·å–æ–¹æ³• (ä¸ºäº†ç®€æ´ï¼Œè¿™é‡Œåªå£°æ˜)
    def _fetch_news_sentiment(self, pair: str) -> Dict:
        # ç»§æ‰¿v1.1å®ç°
        return {'sentiment_score': 0.0, 'news_count': 0, 'positive_ratio': 0.0, 'negative_ratio': 0.0, 'timestamp': time.time()}

    def _fetch_social_heat(self, pair: str) -> Dict:
        # ç»§æ‰¿v1.1å®ç°
        return {'mention_count': 0, 'sentiment_trend': 0.0, 'engagement_score': 0.0, 'heat_index': 0.0, 'timestamp': time.time()}

    def informative_pairs(self):
        pairs = self.dp.current_whitelist()
        informative_pairs = []
        for pair in pairs:
            informative_pairs.append((pair, '15m'))
            informative_pairs.append((pair, '4h'))
        return informative_pairs

    def populate_indicators(self, dataframe: DataFrame, metadata: dict) -> DataFrame:
        """è®¡ç®—æš´æ¶¨æ£€æµ‹æŒ‡æ ‡ - v1.2 MLå¢å¼ºç‰ˆ"""

        # è·å–å¤šæ—¶é—´æ¡†æ¶æ•°æ®
        dataframe_15m = self.dp.get_pair_dataframe(pair=metadata['pair'], timeframe='15m')
        dataframe_4h = self.dp.get_pair_dataframe(pair=metadata['pair'], timeframe='4h')
        dataframe = merge_informative_pair(dataframe, dataframe_15m, self.timeframe, '15m', ffill=True)
        dataframe = merge_informative_pair(dataframe, dataframe_4h, self.timeframe, '4h', ffill=True)

        # v1.0 & v1.1 åŸºç¡€æŒ‡æ ‡ (ç»§æ‰¿æ‰€æœ‰ç°æœ‰æŒ‡æ ‡)
        # ç§»åŠ¨å¹³å‡çº¿
        dataframe['ema_20'] = ta.EMA(dataframe, timeperiod=20)
        dataframe['ema_50'] = ta.EMA(dataframe, timeperiod=50)
        dataframe['sma_200'] = ta.SMA(dataframe, timeperiod=200)

        # RSI
        dataframe['rsi'] = ta.RSI(dataframe, timeperiod=14)
        dataframe['rsi_15m'] = dataframe['rsi_15m']

        # MACD
        macd, macdsignal, macdhist = ta.MACD(dataframe, fastperiod=12, slowperiod=26, signalperiod=9)
        dataframe['macd'] = macd
        dataframe['macd_signal'] = macdsignal
        dataframe['macd_hist'] = macdhist

        # å¸ƒæ—å¸¦
        bb_upper, bb_middle, bb_lower = ta.BBANDS(dataframe, timeperiod=20, nbdevup=2, nbdevdn=2)
        dataframe['bb_upper'] = bb_upper
        dataframe['bb_middle'] = bb_middle
        dataframe['bb_lower'] = bb_lower
        dataframe['bb_width'] = (bb_upper - bb_lower) / bb_middle
        dataframe['price_position_bb'] = (dataframe['close'] - bb_lower) / (bb_upper - bb_lower)

        # ATR
        dataframe['atr'] = ta.ATR(dataframe, timeperiod=14)
        dataframe['atr_percent'] = dataframe['atr'] / dataframe['close'] * 100

        # æˆäº¤é‡æŒ‡æ ‡
        dataframe['vol_sma_20'] = dataframe['volume'].rolling(20).mean()
        dataframe['vol_sma_50'] = dataframe['volume'].rolling(50).mean()
        dataframe['vol_ratio_20'] = dataframe['volume'] / dataframe['vol_sma_20']
        dataframe['vol_ratio_50'] = dataframe['volume'] / dataframe['vol_sma_50']
        dataframe['vol_surge'] = ((dataframe['vol_ratio_20'] > self.volume_surge_threshold.value) |
                                 (dataframe['vol_ratio_50'] > self.volume_surge_threshold.value * 0.8)).astype(int)

        dataframe['obv'] = ta.OBV(dataframe)
        dataframe['obv_sma'] = dataframe['obv'].rolling(20).mean()
        dataframe['obv_trend'] = np.where(dataframe['obv'] > dataframe['obv_sma'], 1, 0)
        dataframe['mfi'] = ta.MFI(dataframe, timeperiod=14)

        # åŠ¨é‡æŒ‡æ ‡
        dataframe['roc_1h'] = ta.ROC(dataframe, timeperiod=1)
        dataframe['roc_4h'] = ta.ROC(dataframe, timeperiod=4)
        dataframe['roc_12h'] = ta.ROC(dataframe, timeperiod=12)
        dataframe['momentum_surge'] = ((dataframe['roc_1h'] > self.price_momentum_threshold.value) |
                                      (dataframe['roc_4h'] > self.price_momentum_threshold.value * 2)).astype(int)

        dataframe['willr'] = ta.WILLR(dataframe, timeperiod=14)
        stoch_k, stoch_d = ta.STOCH(dataframe)
        dataframe['stoch_k'] = stoch_k
        dataframe['stoch_d'] = stoch_d

        # çªç ´æ£€æµ‹
        dataframe['ema_breakout'] = ((dataframe['close'] > dataframe['ema_20']) &
                                    (dataframe['close'].shift(1) <= dataframe['ema_20'].shift(1))).astype(int)

        dataframe['resistance_level'] = dataframe['high'].rolling(50).max()
        dataframe['resistance_breakout'] = ((dataframe['close'] > dataframe['resistance_level'].shift(1)) &
                                          (dataframe['volume'] > dataframe['vol_sma_20'])).astype(int)

        # åè½¬ä¿¡å·
        dataframe['rsi_reversal'] = ((dataframe['rsi'] < 30) & (dataframe['rsi'] > dataframe['rsi'].shift(1)) &
                                   (dataframe['rsi'] > self.rsi_recovery_threshold.value)).astype(int)

        dataframe['macd_golden_cross'] = ((dataframe['macd'] > dataframe['macd_signal']) &
                                        (dataframe['macd'].shift(1) <= dataframe['macd_signal'].shift(1)) &
                                        (dataframe['macd_hist'] > 0)).astype(int)

        # è·å–å¤–éƒ¨æ•°æ®
        try:
            current_pair = metadata['pair']

            # æ–°é—»å’Œç¤¾äº¤æ•°æ® (ç»§æ‰¿v1.1)
            news_data = self._fetch_news_sentiment(current_pair)
            social_data = self._fetch_social_heat(current_pair)

            dataframe['news_sentiment_score'] = news_data.get('sentiment_score', 0.0)
            dataframe['news_count'] = news_data.get('news_count', 0)
            dataframe['news_positive_ratio'] = news_data.get('positive_ratio', 0.0)
            dataframe['social_mention_count'] = social_data.get('mention_count', 0)
            dataframe['social_sentiment_trend'] = social_data.get('sentiment_trend', 0.0)
            dataframe['social_heat_index'] = social_data.get('heat_index', 0.0)

            # v1.2 æ–°å¢æ•°æ®
            if self.enable_onchain_analysis.value:
                onchain_data = self._get_onchain_data(current_pair)
                dataframe['whale_transactions'] = onchain_data.get('whale_transactions', 0)
                dataframe['exchange_flow_ratio'] = onchain_data.get('exchange_outflow', 0) / max(onchain_data.get('exchange_inflow', 1), 1)

            if self.enable_futures_analysis.value:
                futures_data = self._get_futures_data(current_pair)
                dataframe['oi_change_24h'] = futures_data.get('oi_change_24h', 0)
                dataframe['funding_rate'] = futures_data.get('funding_rate', 0)
                dataframe['long_short_ratio'] = futures_data.get('long_short_ratio', 1)

        except Exception as e:
            logger.warning(f"å¤–éƒ¨æ•°æ®è·å–å¤±è´¥: {e}")
            # è®¾ç½®é»˜è®¤å€¼
            for col in ['news_sentiment_score', 'news_count', 'news_positive_ratio',
                       'social_mention_count', 'social_sentiment_trend', 'social_heat_index',
                       'whale_transactions', 'exchange_flow_ratio', 'oi_change_24h',
                       'funding_rate', 'long_short_ratio']:
                if col not in dataframe.columns:
                    dataframe[col] = 0.0

        # ==================== v1.2 å¢å¼ºè¯„åˆ†ç³»ç»Ÿ ====================

        # v1.0 & v1.1 åŸºç¡€è¯„åˆ†
        dataframe['volume_score'] = (dataframe['vol_surge'] * 25 +
                                   (dataframe['vol_ratio_20'] > 2.0).astype(int) * 15 +
                                   dataframe['obv_trend'] * 10)

        dataframe['momentum_score'] = (dataframe['momentum_surge'] * 25 +
                                     (dataframe['roc_1h'] > 0.05).astype(int) * 15 +
                                     (dataframe['roc_4h'] > 0.10).astype(int) * 10)

        dataframe['technical_score'] = (dataframe['ema_breakout'] * 20 +
                                      dataframe['resistance_breakout'] * 25 +
                                      dataframe['macd_golden_cross'] * 15 +
                                      dataframe['rsi_reversal'] * 20)

        dataframe['pattern_score'] = ((dataframe['price_position_bb'] < 0.2).astype(int) * 10 +
                                    (dataframe['willr'] > -20).astype(int) * 10)

        dataframe['sentiment_score'] = ((dataframe['news_sentiment_score'] > 0.1).astype(int) * 20 +
                                      (dataframe['news_positive_ratio'] > 0.6).astype(int) * 15 +
                                      (dataframe['news_count'] > 2).astype(int) * 10) * self.sentiment_weight.value

        dataframe['social_score'] = ((dataframe['social_heat_index'] > 0.3).astype(int) * 25 +
                                   (dataframe['social_sentiment_trend'] > 0.1).astype(int) * 15 +
                                   (dataframe['social_mention_count'] > 10).astype(int) * 10) * self.social_heat_weight.value

        # v1.2 æ–°å¢è¯„åˆ†
        dataframe['onchain_score'] = 0.0
        if self.enable_onchain_analysis.value:
            dataframe['onchain_score'] = ((dataframe['whale_transactions'] > 5).astype(int) * 20 +
                                        (dataframe['exchange_flow_ratio'] > 1.2).astype(int) * 15) * self.onchain_weight.value

        dataframe['futures_score'] = 0.0
        if self.enable_futures_analysis.value:
            dataframe['futures_score'] = ((dataframe['oi_change_24h'] > 10).astype(int) * 15 +
                                        (abs(dataframe['funding_rate']) > 0.005).astype(int) * 10 +
                                        ((dataframe['long_short_ratio'] > 1.5) | (dataframe['long_short_ratio'] < 0.7)).astype(int) * 10) * self.futures_oi_weight.value

        # MLé¢„æµ‹è¯„åˆ†
        dataframe['ml_score'] = 0.0
        if ML_AVAILABLE and self.enable_ml_predictions.value and self.ml_model is not None:
            try:
                # ä¸ºæœ€æ–°çš„å‡ ä¸ªæ•°æ®ç‚¹ç”ŸæˆMLé¢„æµ‹
                for i in range(max(1, len(dataframe) - 5), len(dataframe)):
                    if i >= 0:
                        row_df = dataframe.iloc[[i]].copy()
                        features_df = self._prepare_ml_features(row_df, metadata['pair'])
                        if not features_df.empty:
                            ml_result = self._get_ml_prediction(features_df)
                            dataframe.iloc[i, dataframe.columns.get_loc('ml_score')] = (
                                ml_result['probability'] * 50 * self.ml_model_weight.value
                            )
            except Exception as e:
                logger.warning(f"MLè¯„åˆ†è®¡ç®—å¤±è´¥: {e}")

        # ç»¼åˆè¯„åˆ† v1.2
        dataframe['explosion_score'] = (dataframe['volume_score'] + dataframe['momentum_score'] +
                                      dataframe['technical_score'] + dataframe['pattern_score'] +
                                      dataframe['sentiment_score'] + dataframe['social_score'] +
                                      dataframe['onchain_score'] + dataframe['futures_score'] +
                                      dataframe['ml_score'])

        # å¤šæ—¶é—´æ¡†æ¶ç¡®è®¤ (å¢å¼ºç‰ˆ)
        dataframe['multi_timeframe_confirm'] = ((dataframe['rsi_15m'] < 70) &
                                              (dataframe['volume_15m'] > dataframe['volume_15m'].rolling(20).mean()) &
                                              (dataframe['close_4h'] > dataframe['close_4h'].shift(1)) &
                                              ((dataframe['news_sentiment_score'] >= 0) | (dataframe['news_count'] == 0)) &
                                              ((dataframe['social_sentiment_trend'] >= -0.2) | (dataframe['social_mention_count'] == 0))).astype(int)

        # æœ€ç»ˆä¿¡å·å¼ºåº¦ v1.2
        base_strength = dataframe['explosion_score'] * (1 + dataframe['multi_timeframe_confirm'] * 0.3)

        # å¤–éƒ¨æ•°æ®åŠ æˆ
        external_boost = 1.0
        if self.enable_sentiment_analysis.value:
            external_boost += dataframe['news_sentiment_score'].clip(0, 0.5) * 0.2
        if self.enable_social_analysis.value:
            external_boost += dataframe['social_heat_index'] * 0.15
        if self.enable_onchain_analysis.value:
            external_boost += (dataframe['whale_transactions'] / 100).clip(0, 0.1)
        if self.enable_futures_analysis.value:
            external_boost += (abs(dataframe['oi_change_24h']) / 100).clip(0, 0.1)

        dataframe['signal_strength'] = base_strength * external_boost

        return dataframe

    def populate_entry_trend(self, dataframe: DataFrame, metadata: dict) -> DataFrame:
        """æš´æ¶¨é¢„è­¦ä¿¡å· - v1.2 MLå¢å¼ºç‰ˆ"""

        # åº”ç”¨è‡ªå®šä¹‰ç­›é€‰
        signal_data = {'pair': metadata['pair']}

        # æé«˜æ½œåŠ›ä¿¡å· (100åˆ†ä»¥ä¸Šï¼Œv1.2æ–°å¢)
        condition_ultra_plus = (
            (dataframe['signal_strength'] >= 100) &
            (dataframe['volume'] > 0) &
            (dataframe['explosion_score'] >= 90) &
            (dataframe['ml_score'] > 15)
        )

        if self._apply_custom_filters(metadata['pair'], signal_data):
            dataframe.loc[condition_ultra_plus, ['enter_long', 'enter_tag']] = (1, 'EXTREME_EXPLOSIVE_POTENTIAL')

        # è¶…é«˜æ½œåŠ›ä¿¡å· (90-99åˆ†)
        condition_ultra = (
            (dataframe['signal_strength'] >= 90) &
            (dataframe['signal_strength'] < 100) &
            (dataframe['volume'] > 0) &
            (dataframe['explosion_score'] >= 80)
        )

        if self._apply_custom_filters(metadata['pair'], signal_data):
            dataframe.loc[condition_ultra, ['enter_long', 'enter_tag']] = (1, 'ULTRA_HIGH_EXPLOSIVE_POTENTIAL')

        # é«˜æ½œåŠ›ä¿¡å· (80-89åˆ†)
        condition_high = (
            (dataframe['signal_strength'] >= 80) &
            (dataframe['signal_strength'] < 90) &
            (dataframe['volume'] > 0) &
            (dataframe['explosion_score'] >= 70)
        )

        if self._apply_custom_filters(metadata['pair'], signal_data):
            dataframe.loc[condition_high, ['enter_long', 'enter_tag']] = (1, 'HIGH_EXPLOSIVE_POTENTIAL')

        # ä¸­ç­‰æ½œåŠ›ä¿¡å· (60-79åˆ†)
        condition_medium = (
            (dataframe['signal_strength'] >= 60) &
            (dataframe['signal_strength'] < 80) &
            (dataframe['volume'] > 0) &
            (dataframe['explosion_score'] >= 50)
        )

        if self._apply_custom_filters(metadata['pair'], signal_data):
            dataframe.loc[condition_medium, ['enter_long', 'enter_tag']] = (1, 'MEDIUM_EXPLOSIVE_POTENTIAL')

        # æ—©æœŸé¢„è­¦ä¿¡å· (45-59åˆ†)
        condition_early = (
            (dataframe['signal_strength'] >= 45) &
            (dataframe['signal_strength'] < 60) &
            (dataframe['volume'] > 0) &
            (dataframe['vol_surge'] == 1)
        )

        if self._apply_custom_filters(metadata['pair'], signal_data):
            dataframe.loc[condition_early, ['enter_long', 'enter_tag']] = (1, 'EARLY_WARNING')

        return dataframe

    def populate_exit_trend(self, dataframe: DataFrame, metadata: dict) -> DataFrame:
        """ä¸è®¾ç½®é€€å‡ºä¿¡å·ï¼Œä»…ç”¨äºç­›é€‰"""
        return dataframe

    def custom_entry_price(self, pair: str, trade: Optional["Trade"], current_time: datetime,
                          proposed_rate: float, entry_tag: Optional[str], side: str, **kwargs) -> float:
        return proposed_rate

    def custom_stake_amount(self, pair: str, current_time: datetime, current_rate: float,
                           proposed_stake: float, min_stake: Optional[float], max_stake: float,
                           leverage: float, entry_tag: Optional[str], side: str, **kwargs) -> float:
        return min_stake if min_stake else 10.0

    def confirm_trade_entry(self, pair: str, order_type: str, amount: float, rate: float,
                           time_in_force: str, current_time: datetime, entry_tag: Optional[str],
                           side: str, **kwargs) -> bool:
        """å‘é€v1.2 MLå¢å¼ºç‰ˆæš´æ¶¨é¢„è­¦æ¶ˆæ¯"""
        dataframe, _ = self.dp.get_analyzed_dataframe(pair=pair, timeframe=self.timeframe)

        if len(dataframe) > 0:
            latest = dataframe.iloc[-1]
            signal_strength = latest['signal_strength']
            explosion_score = latest['explosion_score']

            # æ„å»ºv1.2å¢å¼ºç‰ˆé¢„è­¦æ¶ˆæ¯
            message = f"""
ğŸš€ æš´æ¶¨é¢„è­¦ v1.2 - {pair} ğŸš€
ğŸ“Š ä¿¡å·å¼ºåº¦: {signal_strength:.1f}
ğŸ’¥ çˆ†å‘è¯„åˆ†: {explosion_score:.1f}
ğŸ·ï¸ ä¿¡å·ç±»å‹: {entry_tag}
ğŸ’° å½“å‰ä»·æ ¼: {rate:.8f}

ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡:
â”œâ”€ 1å°æ—¶æ¶¨å¹…: {latest['roc_1h']:.2%}
â”œâ”€ æˆäº¤é‡æ¯”ç‡: {latest['vol_ratio_20']:.1f}x
â””â”€ RSI: {latest['rsi']:.1f}

ğŸ¤– AIå¢å¼ºä¿¡å·:
â”œâ”€ MLè¯„åˆ†: {latest['ml_score']:.1f}
â”œâ”€ æ–°é—»æƒ…ç»ª: {latest['news_sentiment_score']:.2f} ({latest['news_count']:.0f}æ¡)
â””â”€ ç¤¾äº¤çƒ­åº¦: {latest['social_heat_index']:.2f}

ğŸ”— é“¾ä¸Š&æœŸè´§:
â”œâ”€ é²¸é±¼äº¤æ˜“: {latest.get('whale_transactions', 0):.0f}ç¬”
â”œâ”€ èµ„é‡‘æµæ¯”: {latest.get('exchange_flow_ratio', 0):.2f}
â””â”€ æŒä»“å˜åŒ–: {latest.get('oi_change_24h', 0):.1f}%

â° {current_time.strftime('%Y-%m-%d %H:%M:%S')}
ğŸ”¥ v1.2 MLå¢å¼ºç®—æ³• - AIè¾…åŠ©æš´æ¶¨é¢„æµ‹ï¼
            """

            self.dp.send_msg(message.strip())

            # ç‰¹æ®Šä¿¡å·é¢å¤–æé†’
            if entry_tag == 'EXTREME_EXPLOSIVE_POTENTIAL':
                self.dp.send_msg(f"ğŸš¨ğŸš¨ğŸš¨ EXTREME ALERT: {pair} AIæ¨¡å‹é¢„æµ‹æå¼ºæš´æ¶¨æ½œåŠ›ï¼ä¿¡å·å¼ºåº¦: {signal_strength:.1f} ğŸš¨ğŸš¨ğŸš¨")
            elif entry_tag == 'ULTRA_HIGH_EXPLOSIVE_POTENTIAL':
                self.dp.send_msg(f"ğŸ”¥ğŸ”¥ğŸ”¥ è¶…é«˜å…³æ³¨: {pair} æ˜¾ç¤ºæå¼ºæš´æ¶¨æ½œåŠ›ï¼ä¿¡å·å¼ºåº¦: {signal_strength:.1f} ğŸ”¥ğŸ”¥ğŸ”¥")

        return False

    def custom_stoploss(self, pair: str, trade: "Trade", current_time: datetime,
                       current_rate: float, current_profit: float, **kwargs) -> float:
        return -0.99